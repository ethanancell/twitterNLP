# twitterNLP
## Overview
This is a repository for a faculty-mentored undergraduate research project in Spring 2020 covering comparative methods for natural language processing of tweets in reference to a real-life disaster or not.

The Kaggle competition link is found at https://www.kaggle.com/c/nlp-getting-started

A rough timeline I followed for the project is the following:
- Get familiarity with some starter methods of natural language processing, including deep-learning and the use of deep-learning libraries
- Apply some of these "starter" methods to the dataset to obtain a model that can output predictions
- Apply more "cutting-edge" methods to this dataset by researching bidirectional models such as BERT
- Explore the benefits and drawbacks of different methods compared to others

## File Guide
Here is a guide to each of the files that is present inside this Github repository:

#### Root level

#### model_scripts

#### data
* train.csv - Labeled training data for the tweets that contained a reference to a real life disaster or not.
* test.csv - Unlabeled test data for the tweets. A submission for the Kaggle competition consists of creating the labels for the data, and then submitting a labeled version of test.csv onto Kaggle's website.
